#!/usr/bin/env tsx

/**
 * Test Optimized WiFi Review Scraper
 * 
 * Tests the optimized scraper that targets 40-50 WiFi reviews per hotel
 * with text pre-filtering and smart early stopping.
 */

import { OptimizedHotelWiFiScraper } from './optimized-scraper'
import { scraperLogger } from '../src/lib/logger'

// Test hotel: Marina Bay Sands
const testHotel = {
  id: 'ddf49728-d779-4615-a9e5-99d6702c9d51',
  name: 'Marina Bay Sands',
  address: '10 Bayfront Avenue, Singapore',
  city_id: 'singapore'
}

async function testOptimizedScraper() {
  let scraper: OptimizedHotelWiFiScraper | null = null
  
  try {
    console.log('üöÄ Testing OPTIMIZED WiFi Review Scraper')
    console.log('==========================================')
    console.log(`Hotel: ${testHotel.name}`)
    console.log(`Target: 40-50 high-quality WiFi reviews`)
    console.log(`Key optimizations:`)
    console.log(`  ‚Ä¢ Text pre-filtering before data extraction`)
    console.log(`  ‚Ä¢ Smart early stopping at 50 reviews`)
    console.log(`  ‚Ä¢ Quality threshold (>50 characters)`)
    console.log(`  ‚Ä¢ Enhanced 5-year date filtering`)
    console.log('')
    
    // Initialize optimized scraper
    console.log('üîß Initializing optimized scraper...')
    scraper = new OptimizedHotelWiFiScraper(6) // 6-12s adaptive rate limiting
    await scraper.initialize()
    
    console.log('‚úÖ Optimized scraper initialized successfully')
    console.log('')
    
    // Test optimized collection
    console.log('‚ö° Starting optimized WiFi review collection...')
    const startTime = Date.now()
    
    const reviews = await scraper.scrapeHotelWiFiReviews(testHotel)
    
    const endTime = Date.now()
    const duration = (endTime - startTime) / 1000
    
    console.log('')
    console.log('üèÜ OPTIMIZED COLLECTION RESULTS')
    console.log('================================')
    console.log(`‚è±Ô∏è  Duration: ${duration.toFixed(1)} seconds`)
    console.log(`üìù WiFi reviews collected: ${reviews.length}`)
    
    if (reviews.length > 0) {
      // Analyze results quality
      const speedMentions = reviews.filter(r => r.extracted_speed).length
      const longReviews = reviews.filter(r => r.review_text.length > 100).length
      const recentReviews = reviews.filter(r => r.review_date.includes('ago') || r.review_date.includes('yesterday')).length
      const absoluteYearReviews = reviews.filter(r => /20\\d{2}/.test(r.review_date)).length
      
      console.log('')
      console.log('üìä Quality Analysis:')
      console.log('===================')
      console.log(`üöÄ Reviews with speed data: ${speedMentions} (${((speedMentions / reviews.length) * 100).toFixed(1)}%)`)
      console.log(`üìñ Detailed reviews (>100 chars): ${longReviews} (${((longReviews / reviews.length) * 100).toFixed(1)}%)`)
      console.log(`üÜï Recent format reviews: ${recentReviews}`)
      console.log(`üìÜ Absolute year reviews: ${absoluteYearReviews}`)
      
      if (speedMentions > 0) {
        const speeds = reviews
          .filter(r => r.extracted_speed)
          .slice(0, 5)
          .map(r => `${r.extracted_speed}Mbps`)
          .join(', ')
        console.log(`üí® Sample speeds: ${speeds}`)
      }
      
      // Show optimization statistics
      const optimizationStats = scraper.getOptimizationStats()
      console.log('')
      console.log('‚ö° Optimization Performance:')
      console.log('===========================')
      console.log(`üìä Elements processed: ${optimizationStats.totalElementsProcessed}`)
      console.log(`üéØ WiFi reviews found: ${optimizationStats.wifiReviewsFound}`)
      console.log(`üìà Efficiency ratio: ${optimizationStats.efficiencyRatio.toFixed(2)}%`)
      console.log(`‚è±Ô∏è  Processing time: ${(optimizationStats.processingTimeMs / 1000).toFixed(1)}s`)
      console.log(`üóìÔ∏è  Old reviews skipped: ${optimizationStats.oldReviewsSkipped}`)
      console.log(`üìè Low quality skipped: ${optimizationStats.lowQualitySkipped}`)
      
      // Compare to previous approach
      const previousApproachElements = 11809 // From our previous test
      const previousDuration = 18 * 60 // ~18 minutes
      const efficiencyImprovement = optimizationStats.efficiencyRatio / 0.5 // vs ~0.5% baseline
      const speedImprovement = previousDuration / (optimizationStats.processingTimeMs / 1000)
      
      console.log('')
      console.log('üöÄ Improvement vs Previous Approach:')
      console.log('====================================')
      console.log(`üìä Elements: ${optimizationStats.totalElementsProcessed} vs ${previousApproachElements} (${((optimizationStats.totalElementsProcessed / previousApproachElements) * 100).toFixed(1)}%)`)
      console.log(`‚ö° Efficiency: ${efficiencyImprovement.toFixed(1)}x better`)
      console.log(`üèÉ Speed: ${speedImprovement.toFixed(1)}x faster`)
      console.log(`üéØ Target achievement: ${reviews.length >= 40 ? '‚úÖ SUCCESS' : reviews.length >= 30 ? 'üî∂ GOOD' : '‚ö†Ô∏è PARTIAL'}`)
      
      if (reviews.length >= 40) {
        console.log('')
        console.log('üéâ OPTIMIZATION SUCCESS!')
        console.log('========================')
        console.log(`‚úÖ Achieved target: ${reviews.length}/50 WiFi reviews`)
        console.log(`‚ö° Massive efficiency gain: ${efficiencyImprovement.toFixed(1)}x improvement`)
        console.log(`üöÄ Speed improvement: ${speedImprovement.toFixed(1)}x faster`)
        console.log(`üìä Ready for 30-hotel Singapore collection`)
        console.log('')
        console.log('üéØ Next Steps:')
        console.log('  1. Scale to all 30 Singapore hotels')
        console.log('  2. Process reviews with AI quirk detection')
        console.log('  3. Generate comprehensive dataset')
        console.log('  4. Expand to London and NYC')
      }
      
    } else {
      console.log('‚ö†Ô∏è  No WiFi reviews collected')
      console.log('This could indicate:')
      console.log('  ‚Ä¢ Network or selector issues')
      console.log('  ‚Ä¢ Hotel may have limited WiFi mentions')
      console.log('  ‚Ä¢ All reviews may be older than 5 years')
    }
    
  } catch (error) {
    console.error('üí• Optimized test failed:', error)
  } finally {
    if (scraper) {
      await scraper.cleanup()
      console.log('')
      console.log('üßπ Optimized scraper cleanup completed')
    }
  }
}

console.log('üéØ OPTIMIZED SCRAPER TEST')
console.log('========================')
console.log('Previous approach: 11,809+ elements in 18+ minutes')
console.log('Optimized approach: Target 40-50 reviews in 3-8 minutes')
console.log('Expected efficiency: 3-7x improvement')
console.log('')

// Run optimized test
testOptimizedScraper().catch(console.error)